# Crawler

Caches all wiki pages into `dump-html` directory.
Organized by first two letters.

Dumps are collected into [dump-html repository](https://github.com/mtasa-typescript/mtasa-wiki-dump-html)

It's private, so, if you would like to use parser, you should create your own dump-html files via the crawler.